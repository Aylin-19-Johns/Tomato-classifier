{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set up data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Splitting data into training and validation sets\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 2 classes.\n",
      "Found 69 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Tomatoes/Train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=['good', 'bad']\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'Tomatoes/Test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=['good', 'bad']  # Explicitly specify class labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the CNN model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ],\n",
    "    name='tomato_classifier'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6338 - accuracy: 0.6875 - val_loss: 2.8359 - val_accuracy: 0.4844\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0758 - accuracy: 0.7500 - val_loss: 0.4609 - val_accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4218 - accuracy: 0.7500 - val_loss: 0.2948 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.7344\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 0.0864 - accuracy: 0.9583 - val_loss: 0.2166 - val_accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.0407 - accuracy: 0.9583 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230365201d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the generators\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brigh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('tomato_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of the pre-trained base model\n",
    "model2 = Sequential([\n",
    "    vgg16_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.9252 - accuracy: 0.3750 - val_loss: 1.5498 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6847 - accuracy: 0.7500 - val_loss: 0.8771 - val_accuracy: 0.6094\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3082 - accuracy: 0.8125 - val_loss: 0.1977 - val_accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9531\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2303dc90c90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the generators\n",
    "model2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brigh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model2.save('tomato_classifier_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023048CDC400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "prediction of model 1\n",
      "The tomato is classified as 'bad'.\n",
      "prediction of model vgg16\n",
      "The tomato is classified as 'bad'.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've trained and saved your model already...\n",
    "\n",
    "# Load the saved models\n",
    "model = tf.keras.models.load_model('tomato_classifier_model.h5')\n",
    "loaded_model = tf.keras.models.load_model('tomato_classifier_VGG16.h5')\n",
    "\n",
    "# Now, assuming you have a new image you want to classify\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_image_path = 'Tomatoes/Test/bad/116_100.jpg'  # Replace with the path to your new image\n",
    "new_img = image.load_img(new_image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "new_img_array = image.img_to_array(new_img)\n",
    "new_img_array = np.expand_dims(new_img_array, axis=0)\n",
    "new_img_array /= 255.  # Normalize the image\n",
    "\n",
    "# Make a prediction using the loaded model\n",
    "prediction = model.predict(new_img_array)\n",
    "prediction1 = loaded_model.predict(new_img_array)\n",
    "\n",
    "# Interpret the prediction\n",
    "print(\"prediction of model 1\")\n",
    "if prediction[0] < 0.5:\n",
    "    print(\"The tomato is classified as 'good'.\")\n",
    "else:\n",
    "    print(\"The tomato is classified as 'bad'.\")\n",
    "\n",
    "print(\"prediction of model vgg16\")\n",
    "if prediction1[0] < 0.5:\n",
    "    print(\"The tomato is classified as 'good'.\")\n",
    "else:\n",
    "    print(\"The tomato is classified as 'bad'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = 150  # Adjust this according to your image size\n",
    "dataset_path = 'Tomatoes'  # Replace this with your dataset path\n",
    "csv_file_path = 'tomato_dataset_with_images.csv'\n",
    "excel_file_path = 'tomato_dataset.xlsx'\n",
    "\n",
    "# Open CSV file in write mode\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Filename', 'Label', 'Image', 'Set'])  # Write header\n",
    "\n",
    "    # Iterate through Train and Test folders\n",
    "    for folder in ['Train', 'Test']:\n",
    "        for class_name in ['good', 'bad']:\n",
    "            class_dir = os.path.join(dataset_path, folder, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "                # Check if the file is an image by attempting to open it with PIL\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                except (IOError, OSError):\n",
    "                    continue  # Skip if it's not an image file\n",
    "\n",
    "                # Convert image to numpy array\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Convert image array to base64 string\n",
    "                img_str = img_array.tobytes()\n",
    "                img_base64 = base64.b64encode(img_str).decode('utf-8')\n",
    "\n",
    "                # Determine if the image is in the 'Train' or 'Test' set\n",
    "                image_set = folder\n",
    "\n",
    "                writer.writerow([file_path, class_name, img_base64, image_set])\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "data.to_excel(excel_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
